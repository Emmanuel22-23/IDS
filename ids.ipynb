{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "np.set_printoptions(precision=3)\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Train_data.csv\")\n",
    "test = pd.read_csv(\"Test_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.head(4))\n",
    "\n",
    "print(\"les données entrainés sont : {} lignes et {} colonnes\".format(train.shape[0],train.shape[1]))\n",
    "\n",
    "print(test.head(4))\n",
    "\n",
    "print(\"les données de test sont : {} lignes et {} colonnes\".format(test.shape[0],test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['num_outbound_cmds'].value_counts())\n",
    "print(test['num_outbound_cmds'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['num_outbound_cmds'], axis=1, inplace=True)\n",
    "test.drop(['num_outbound_cmds'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "cols = train.select_dtypes(include=['float64','int64']).columns\n",
    "sc_train = scaler.fit_transform(train.select_dtypes(include=['float64','int64']))\n",
    "sc_test = scaler.fit_transform(test.select_dtypes(include=['float64','int64']))\n",
    "\n",
    "\n",
    "sc_traindf = pd.DataFrame(sc_train, columns = cols)\n",
    "sc_testdf = pd.DataFrame(sc_test, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# extract categorical attributes from both training and test sets \n",
    "cattrain = train.select_dtypes(include=['object']).copy()\n",
    "cattest = test.select_dtypes(include=['object']).copy()\n",
    "\n",
    "# encode the categorical attributes\n",
    "traincat = cattrain.apply(encoder.fit_transform)\n",
    "testcat = cattest.apply(encoder.fit_transform)\n",
    "\n",
    "# separate target column from encoded data \n",
    "enctrain = traincat.drop(['class'], axis=1)\n",
    "cat_Ytrain = traincat[['class']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.concat([sc_traindf,enctrain],axis=1)\n",
    "train_y = train['class']\n",
    "train_x.shape\n",
    "\n",
    "\n",
    "\n",
    "test_df = pd.concat([sc_testdf,testcat],axis=1)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "\n",
    "rfc.fit(train_x, train_y)\n",
    "# extraction des features importants !!\n",
    "score = np.round(rfc.feature_importances_,3)\n",
    "importances = pd.DataFrame({'feature':train_x.columns,'importance':score})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "# plot importances, plot nous permet d'afficher !!\n",
    "plt.rcParams['figure.figsize'] = (11, 4)\n",
    "importances.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "import itertools\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# créons le modèle RFE et sélectionnons 10 attributes\n",
    "rfe = RFE(rfc, n_features_to_select=15)\n",
    "rfe = rfe.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "feature_map = [(i, v) for i, v in itertools.zip_longest(rfe.get_support(), train_x.columns)]\n",
    "selected_features = [v for i, v in feature_map if i==True]\n",
    "\n",
    "selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(train_x,train_y,train_size=0.70, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Entrainons le modèle du cas plus proche voisin\n",
    "KNN_Classifier = KNeighborsClassifier(n_jobs=-1)\n",
    "KNN_Classifier.fit(X_train, Y_train); \n",
    "\n",
    "# Entrainons le modèle de la regression logistique\n",
    "LGR_Classifier = LogisticRegression(n_jobs=-1, random_state=0)\n",
    "LGR_Classifier.fit(X_train, Y_train);\n",
    "\n",
    "# Entrainons le modèle Gaussian Naive Baye\n",
    "BNB_Classifier = BernoulliNB()\n",
    "BNB_Classifier.fit(X_train, Y_train)\n",
    "            \n",
    "# Entrainons le modèle l'arbre de décision\n",
    "DTC_Classifier = tree.DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "DTC_Classifier.fit(X_train, Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "models = []\n",
    "models.append(('Naive Baye Classifier', BNB_Classifier))\n",
    "models.append(('Decision Tree Classifier', DTC_Classifier))   #arbre de décision monsieur Skofild fullstack !!!\n",
    "models.append(('KNeighborsClassifier', KNN_Classifier))\n",
    "models.append(('LogisticRegression', LGR_Classifier))\n",
    "\n",
    "for i, v in models:\n",
    "    scores = cross_val_score(v, X_train, Y_train, cv=10)\n",
    "    accuracy = metrics.accuracy_score(Y_train, v.predict(X_train))\n",
    "    confusion_matrix = metrics.confusion_matrix(Y_train, v.predict(X_train))\n",
    "    classification = metrics.classification_report(Y_train, v.predict(X_train))\n",
    "    print()\n",
    "    print('============================== {} Evaluation du modèle =============================='.format(i))\n",
    "    print()\n",
    "    print (\"Moyenne de la Cross Validation Score:\" \"\\n\", scores.mean())\n",
    "    print()\n",
    "    print (\"Accuracy du modèle:\" \"\\n\", accuracy)\n",
    "    print()\n",
    "    print(\"Matrice de confusion:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"rapport de classification:\" \"\\n\", classification) \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in models:\n",
    "    accuracy = metrics.accuracy_score(Y_test, v.predict(X_test))\n",
    "    confusion_matrix = metrics.confusion_matrix(Y_test, v.predict(X_test))\n",
    "    classification = metrics.classification_report(Y_test, v.predict(X_test))\n",
    "    print()\n",
    "    print('============================== {} résultat du test du modèle =============================='.format(i))\n",
    "    print()\n",
    "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
    "    print()\n",
    "    print(\"matrice de confusion:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"rapport de classification:\" \"\\n\", classification) \n",
    "    print()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prédiction en utilisant l'algorithme KNN\n",
    "\n",
    "pred_knn = KNN_Classifier.predict(test_df)\n",
    "pred_NB = BNB_Classifier.predict(test_df)\n",
    "pred_log = LGR_Classifier.predict(test_df)\n",
    "pred_dt = DTC_Classifier.predict(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hello Emmanuel skofild fullstack !!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0+"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
